{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KoNLPy 의 Komoran 을 이용하여 라라랜드 영화 리뷰를 토크나이징 한 텍스트를 `lalaland_komoran.txt` 에, 원문을 `lalaland.txt` 에 저장하였습니다. 총 15,595 건의 영화평입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15595 15595\n"
     ]
    }
   ],
   "source": [
    "# Komoran tokenized La La Land review\n",
    "with open('./lalaland_komoran.txt', encoding='utf-8') as f:\n",
    "    sents = [sent.strip() for sent in f]\n",
    "\n",
    "with open('./lalaland.txt', encoding='utf-8') as f:\n",
    "    texts = [sent.strip() for sent in f]\n",
    "\n",
    "print(len(sents), len(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextRank 에서는 word cooccurrence graph 를 만들 때 명사와 동사 등을 이용할 것을 제안하였습니다. 이는 조사나 관사와 같이 의미를 지니지 않으면서도 자주 이용되는 단어들이 높은 PageRank 를 가지게 되는 것을 방지하기 위해서입니다.\n",
    "\n",
    "Komoran 에서의 명사 (NN), 어근 (XR), 형용사 (VA), 동사 (VV) 만을 이용하여 word cooccurrence graph 를 만듭니다. window 를 -1 로 설정하면 한 문장에서 얼마나 떨어져 있던지 상관없이 cooccurrence 를 계산하며, window 가 1 보다 클 경우에는 해당 간격만큼만 떨어진 단어들 간에만 cooccurrence 를 인정합니다.\n",
    "\n",
    "학습 결과 `영화`, `음악`, `꿈`, `마지막` 같은 라라랜드의 엔딩을 의미하는 단어들이 핵심 단어로 선택되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영화/NNG (1.73e+02)\n",
      "보/VV (1.29e+02)\n",
      "좋/VA (65.5)\n",
      "하/VV (52.0)\n",
      "것/NNB (47.4)\n",
      "같/VA (45.4)\n",
      "영화/NNP (43.8)\n",
      "음악/NNG (43.6)\n",
      "꿈/NNG (41.4)\n",
      "있/VV (40.8)\n",
      "없/VA (35.9)\n",
      "마지막/NNG (31.9)\n",
      "수/NNB (30.1)\n",
      "사랑/NNG (28.3)\n",
      "아름답/VA (26.5)\n",
      "현실/NNG (24.8)\n",
      "되/VV (23.9)\n",
      "노래/NNG (23.4)\n",
      "생각/NNG (23.2)\n",
      "스토리/NNP (21.4)\n",
      "번/NNB (20.3)\n",
      "거/NNB (19.7)\n",
      "최고/NNG (19.2)\n",
      "때/NNG (19.1)\n",
      "사람/NNG (19.0)\n",
      "여운/NNP (17.5)\n",
      "뮤지컬/NNP (16.9)\n",
      "나오/VV (16.5)\n",
      "듯/NNB (16.1)\n",
      "영상미/NNG (16.0)\n"
     ]
    }
   ],
   "source": [
    "from textrank import KeywordSummarizer\n",
    "\n",
    "def komoran_tokenize(sent):\n",
    "    words = sent.split()\n",
    "    words = [w for w in words if ('/NN' in w or '/XR' in w or '/VA' in w or '/VV' in w)]\n",
    "    return words\n",
    "\n",
    "keyword_extractor = KeywordSummarizer(\n",
    "    tokenize = komoran_tokenize,\n",
    "    window = -1,\n",
    "    verbose = False\n",
    ")\n",
    "keywords = keyword_extractor.summarize(sents, topk=30)\n",
    "for word, rank in keywords:\n",
    "    print('{} ({:.3})'.format(word, rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 모든 단어를 이용할 경우에는 조사 (JKG, JX, JKS, ... ) 어미 (EC, EP, ... ) 등이 핵심 단어로 선택됩니다. 이는 word cooccurrence graph 는 사실상 출현빈도가 높은 단어들이 높은 Rank 를 가지도록 유도하기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ㄴ/ETM (1.24e+02)\n",
      "고/EC (1.03e+02)\n",
      "영화/NNG (96.8)\n",
      "는/ETM (94.6)\n",
      "이/VCP (92.3)\n",
      "이/JKS (92.0)\n",
      "하/XSV (85.2)\n",
      "에/JKB (79.0)\n",
      "았/EP (76.1)\n",
      "보/VV (73.5)\n",
      "었/EP (72.8)\n",
      "다/EC (68.3)\n",
      "을/JKO (64.2)\n",
      "하/XSA (58.8)\n",
      "의/JKG (58.4)\n",
      "도/JX (52.7)\n",
      "ㄹ/ETM (50.2)\n",
      "가/JKS (47.2)\n",
      "게/EC (46.7)\n",
      "는/JX (42.3)\n",
      "어/EC (37.9)\n",
      "좋/VA (37.6)\n",
      "를/JKO (34.3)\n",
      "아/EC (33.8)\n",
      "은/ETM (33.7)\n",
      "들/XSN (32.6)\n",
      "은/JX (32.0)\n",
      "하/VV (29.8)\n",
      "것/NNB (26.7)\n",
      "과/JC (26.5)\n"
     ]
    }
   ],
   "source": [
    "keyword_extractor = KeywordSummarizer(\n",
    "    tokenize=lambda x:x.split(),\n",
    "    verbose = False\n",
    ")\n",
    "keywords = keyword_extractor.summarize(sents, topk=30)\n",
    "for word, rank in keywords:\n",
    "    print('{} ({:.3})'.format(word, rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "window 의 크기를 바꾼다 하여도 큰 변화는 없습니다. 약간의 순위 변동은 있지만, 큰 맥락이 변하지는 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영화/NNG (1.9e+02)\n",
      "보/VV (1.5e+02)\n",
      "좋/VA (80.8)\n",
      "하/VV (51.2)\n",
      "음악/NNG (50.8)\n",
      "영화/NNP (50.3)\n",
      "것/NNB (44.6)\n",
      "꿈/NNG (42.5)\n",
      "같/VA (40.7)\n",
      "있/VV (40.6)\n",
      "없/VA (35.5)\n",
      "마지막/NNG (33.7)\n",
      "아름답/VA (32.1)\n",
      "사랑/NNG (30.4)\n",
      "수/NNB (29.5)\n",
      "현실/NNG (27.9)\n",
      "노래/NNG (26.1)\n",
      "최고/NNG (23.8)\n",
      "스토리/NNP (23.6)\n",
      "생각/NNG (23.5)\n",
      "되/VV (23.1)\n",
      "번/NNB (22.7)\n",
      "여운/NNP (22.1)\n",
      "감동/NNG (19.1)\n",
      "사람/NNG (18.6)\n",
      "때/NNG (18.0)\n",
      "거/NNB (18.0)\n",
      "지루/XR (17.6)\n",
      "영상미/NNG (16.8)\n",
      "재밌/VA (16.3)\n"
     ]
    }
   ],
   "source": [
    "keyword_extractor = KeywordSummarizer(\n",
    "    tokenize = komoran_tokenize,\n",
    "    window = 2,\n",
    "    verbose = False\n",
    ")\n",
    "keywords = keyword_extractor.summarize(sents, topk=30)\n",
    "for word, rank in keywords:\n",
    "    print('{} ({:.3})'.format(word, rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "핵심 문장을 선택하기 위하여 문장 간 유사도를 계산한 다음, `min_sim` 이상의 유사도를 지니는 문장 간에 adjacent sentence graph 를 만듭니다. 그리고 여기에 PageRank 를 적용하여 핵심 문장을 선택합니다.\n",
    "\n",
    "텍스트를 출력할 때에는 토크나이징된 문장은 가독이 어렵기 때문에 원 텍스트를 이용하여 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructing sentence graph was constructed from 15595 sents\n",
      "trained TextRank. n sentences = 15595\n",
      "#5 (2.56e+02) : 시사회 보고 왔어요 꿈과 사랑에 관한 이야기인데 뭔가 진한 여운이 남는 영화예요\n",
      "\n",
      "#14 (1.17e+02) : 시사회 갔다왔어요 제가 라이언고슬링팬이라서 하는말이아니고 너무 재밌어요 꿈과 현실이 잘 보여지는영화 사랑스런 영화 전 개봉하면 또 볼생각입니당\n",
      "\n",
      "#17 (94.4) : 시사회에서 보고왔는데 여운쩔었다 엠마스톤과 라이언 고슬링의 케미가 도입부의 강렬한음악좋았고 예고편에 나왓던 오디션 노래 감동적이어서 눈물나왔다ㅠ 이영화는 위플래쉬처럼 꼭 영화관에봐야함 색감 노래 배우 환상적인 영화\n",
      "\n",
      "#27 (77.3) : 방금 시사회로 봤는데 인생영화 하나 또 탄생했네 롱테이크 촬영이 예술 영상이 넘나 아름답고 라이언고슬링의 멋진 피아노 연주 엠마스톤과의 춤과 노래 눈과 귀가 호강한다 재미를 기대하면 약간 실망할수도 있지만 충분히 훌륭한 영화\n",
      "\n",
      "#6 (65.9) : 황홀하고 따뜻한 꿈이었어요 imax로 또 보려합니다 좋은 영화 시사해주셔서 감사해요\n",
      "\n",
      "#18 (56.3) : 시사회 갔다왔는데 실망했어요 너무 기대하면 안될 것 같습니다 꿈 같은 영화 마법 같은 영화는 맞는데 꿈과 마법이 깨지는 순간 이 영화는 어디로 가고 있는가 하는 생각이 들었어요 할 말은 많지만 욕먹을까봐 줄임\n",
      "\n",
      "#1 (55.7) : 사랑과 꿈 그 흐름의 아름다움을 음악과 영상으로 최대한 담아놓았다 배우들 연기는 두말할것없고\n",
      "\n",
      "#26 (54.2) : 시사회 봤네요 영화를 보고나면 지금 내 옆에 있는 사람이 소중하게 느껴질것\n",
      "\n",
      "#60 (51.9) : 최고의 뮤지컬 영화영화를 보는 내내 꿈 속에 있는듯한 황홀함\n",
      "\n",
      "#51 (50.7) : 이번 부산국제영화제서 봤습니다 정말 역대 100 최고의 영화라 말할수있을 정도로 훌륭하고 신나고 즐겁고 재밌었습니다 두번보고 세번보고 평생소장하고 싶은 영화로 추천합니다 사랑하는 사람과 함께 황홀경에 빠져보시길\n",
      "\n",
      "#22 (49.9) : 방금 시사회보고 왔어요 정말 힘든 하루였는데 눈이랑 귀가 절로 호강한 영화였어요ㅜ개봉하면 혼자 또 보러갈까해요 마지막에 라이언고슬링의 피아노연주는 아직도 여운이 남네요 뭔가 현실적이여서 더 와닿는 음악영화 좋아하시는분들은 꼭 보시길\n",
      "\n",
      "#21 (48.8) : 방금 전 시사회에서 보고 왔습니다 귀와 눈이 모두 즐거운 놀랍고 환상적인 영화입나다 강추합니다\n",
      "\n",
      "#3 (42.0) : 방금 시사회 보고 왔어요 배우들 매력이 눈을 뗄 수가 없게 만드네요 한편의 그림 같은 장면들도 많고 음악과 춤이 눈과 귀를 사로 잡았어요 한번 더 보고 싶네요\n",
      "\n",
      "#159 (40.7) : 두번봐도 감동이 전해지는 영화 인생영화라고 칭할 정도로 감동 받았다 음악과 영상미에 가장 먼저 매료되었고 내용도 꿈을 찾아가는 것이 현재 청춘들이 느낄 수 있는 감정들을 충분히 잘 표현했다고 생각한다 본지 꽤 되었지만 한달 째 ost에 빠져사는중\n",
      "\n",
      "#132 (38.0) : 생각보단 별루엿어요 연출과 음악은 좋았으나 그이상은 아니었습니다 너무 기대하구 봐서 그런것도 같유요\n",
      "\n",
      "#7 (37.7) : 엠마스톤의 노래 솜씨도 보겠군\n",
      "\n",
      "#20 (37.7) : 음악 속 그들에게 빠져들었다 꽤나 오래토록 라라랜드 노래가 내 하루에 떠오를 것 같다\n",
      "\n",
      "#2 (37.2) : 지금껏 영화 평가 해본 적이 없는데 진짜 최고네요 색감 스토리 음악 연기 모두ㅜㅜ최고입니다\n",
      "\n",
      "#187 (36.6) : 저가 본 영화중에서 두번째로 최고인 영화였던것같습니다 노래도너무좋았고 정말 한 장면도 놓칠수없었습니다 재밌었고 앞으로도 이런 비슷한 영화들이나와도 괜찮을것같다 싶었던것같습니다\n",
      "\n",
      "#47 (36.1) : 이 영화는 마법이다\n",
      "\n",
      "#35 (34.1) : 이거 2번보고 3번 보세요 진짜 최고입니다\n",
      "\n",
      "#171 (33.9) : 보는 내내 좋은 음악들 덕에 귀가 즐거웠고 현실적인 결말이 인상깊었다 생각하게 만드는 영화\n",
      "\n",
      "#39 (33.6) : 마지막에 엠마 스톤이랑 헤어져서 너무 슬펐네요 슬프면서도 현실적이라고 할까요 마지막 장면의 라이언고슬링의 피아노 연주는 진짜 여운이 최고였습니다 올해 최고의 영화입니다\n",
      "\n",
      "#52 (33.3) : 엠마스톤이랑 라이언고슬링이 또 만났네 넘좋다 꼭봐야지 혼자 꼭\n",
      "\n",
      "#15 (33.0) : 이 영화는 여름에 보면 안되겠음 색조합 난리나는 영상미에 취해 자꾸 입이 벌어져 날파리가 들어갈 위험이 있고 사운드에 지려 여름엔 암모니아 냄새가 더 진동할 수 있음\n",
      "\n",
      "#121 (32.2) : 눈과 귀를 사로잡는 라라랜드 영화를 보고 난 후 여운이 많이 남는 영화에요 중간 중간 동화적 요소가 조금 과한듯해서 당황했지만 주인공들의 연기력과 호흡이 정말 좋았던거 같아요\n",
      "\n",
      "#181 (31.2) : 정말 좋은 영화네요색감 화면 음악 연기 극본 뭐하나 빠지는게 없는 영화입니다굳이 보러갈만한 가치가 있네요약간 냉소적인 시선 현실적인 엔딩까지 모두 좋습니다다만 뮤지컬영화다 보니 좀 길다싶은 테이크도 있네요 그래도 꼭 한번 볼만한 영화\n",
      "\n",
      "#73 (30.5) : 부국제에서 봤는데 뭐 끝이네요 너무너무너무나도 재미있게 즐겁게 감동받으며 봤습니다 감독 배우 때문에 기대를 많이 받는것 같은데 그냥 둘다 최고입니다\n",
      "\n",
      "#120 (30.1) : 벌써 두번째 보는 영화인데요 아무리 봐도 잊혀지지 않네요\n",
      "\n",
      "#24 (28.7) : 엠마 스톤과 라이언 고슬링 여러번 만났지만 라라랜드에서 가장 빛난다 영화가 끝나고 나오면서 절로 흥얼거리게 되는 노래에서 이 영화가 올 겨울 가장 뜨거운 영화가 되지 않을까 생각하게 된다\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from textrank import KeysentenceSummarizer\n",
    "\n",
    "summarizer = KeysentenceSummarizer(\n",
    "    tokenize = komoran_tokenize,\n",
    "    min_sim = 0.5,\n",
    "    verbose = True\n",
    ")\n",
    "keysents = summarizer.summarize(sents)\n",
    "for idx, rank, komoran_sent in keysents:\n",
    "    print('#{} ({:.3}) : {}'.format(idx, rank, texts[idx]), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래의 뉴스 기사에 대하여 3 개의 핵심 문장을 추출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [\n",
    "    '오패산터널 총격전 용의자 검거 서울 연합뉴스 경찰 관계자들이 19일 오후 서울 강북구 오패산 터널 인근에서 사제 총기를 발사해 경찰을 살해한 용의자 성모씨를 검거하고 있다 성씨는 검거 당시 서바이벌 게임에서 쓰는 방탄조끼에 헬멧까지 착용한 상태였다',\n",
    "    '서울 연합뉴스 김은경 기자 사제 총기로 경찰을 살해한 범인 성모 46 씨는 주도면밀했다',\n",
    "    '경찰에 따르면 성씨는 19일 오후 강북경찰서 인근 부동산 업소 밖에서 부동산업자 이모 67 씨가 나오기를 기다렸다 이씨와는 평소에도 말다툼을 자주 한 것으로 알려졌다',\n",
    "    '이씨가 나와 걷기 시작하자 성씨는 따라가면서 미리 준비해온 사제 총기를 이씨에게 발사했다 총알이 빗나가면서 이씨는 도망갔다 그 빗나간 총알은 지나가던 행인 71 씨의 배를 스쳤다',\n",
    "    '성씨는 강북서 인근 치킨집까지 이씨 뒤를 쫓으며 실랑이하다 쓰러뜨린 후 총기와 함께 가져온 망치로 이씨 머리를 때렸다',\n",
    "    '이 과정에서 오후 6시 20분께 강북구 번동 길 위에서 사람들이 싸우고 있다 총소리가 났다 는 등의 신고가 여러건 들어왔다',\n",
    "    '5분 후에 성씨의 전자발찌가 훼손됐다는 신고가 보호관찰소 시스템을 통해 들어왔다 성범죄자로 전자발찌를 차고 있던 성씨는 부엌칼로 직접 자신의 발찌를 끊었다',\n",
    "    '용의자 소지 사제총기 2정 서울 연합뉴스 임헌정 기자 서울 시내에서 폭행 용의자가 현장 조사를 벌이던 경찰관에게 사제총기를 발사해 경찰관이 숨졌다 19일 오후 6시28분 강북구 번동에서 둔기로 맞았다 는 폭행 피해 신고가 접수돼 현장에서 조사하던 강북경찰서 번동파출소 소속 김모 54 경위가 폭행 용의자 성모 45 씨가 쏜 사제총기에 맞고 쓰러진 뒤 병원에 옮겨졌으나 숨졌다 사진은 용의자가 소지한 사제총기',\n",
    "    '신고를 받고 번동파출소에서 김창호 54 경위 등 경찰들이 오후 6시 29분께 현장으로 출동했다 성씨는 그사이 부동산 앞에 놓아뒀던 가방을 챙겨 오패산 쪽으로 도망간 후였다',\n",
    "    '김 경위는 오패산 터널 입구 오른쪽의 급경사에서 성씨에게 접근하다가 오후 6시 33분께 풀숲에 숨은 성씨가 허공에 난사한 10여발의 총알 중 일부를 왼쪽 어깨 뒷부분에 맞고 쓰러졌다',\n",
    "    '김 경위는 구급차가 도착했을 때 이미 의식이 없었고 심폐소생술을 하며 병원으로 옮겨졌으나 총알이 폐를 훼손해 오후 7시 40분께 사망했다',\n",
    "    '김 경위는 외근용 조끼를 입고 있었으나 총알을 막기에는 역부족이었다',\n",
    "    '머리에 부상을 입은 이씨도 함께 병원으로 이송됐으나 생명에는 지장이 없는 것으로 알려졌다',\n",
    "    '성씨는 오패산 터널 밑쪽 숲에서 오후 6시 45분께 잡혔다',\n",
    "    '총격현장 수색하는 경찰들 서울 연합뉴스 이효석 기자 19일 오후 서울 강북구 오패산 터널 인근에서 경찰들이 폭행 용의자가 사제총기를 발사해 경찰관이 사망한 사건을 조사 하고 있다',\n",
    "    '총 때문에 쫓던 경관들과 민간인들이 몸을 숨겼는데 인근 신발가게 직원 이모씨가 다가가 성씨를 덮쳤고 이어 현장에 있던 다른 상인들과 경찰이 가세해 체포했다',\n",
    "    '성씨는 경찰에 붙잡힌 직후 나 자살하려고 한 거다 맞아 죽어도 괜찮다 고 말한 것으로 전해졌다',\n",
    "    '성씨 자신도 경찰이 발사한 공포탄 1발 실탄 3발 중 실탄 1발을 배에 맞았으나 방탄조끼를 입은 상태여서 부상하지는 않았다',\n",
    "    '경찰은 인근을 수색해 성씨가 만든 사제총 16정과 칼 7개를 압수했다 실제 폭발할지는 알 수 없는 요구르트병에 무언가를 채워두고 심지를 꽂은 사제 폭탄도 발견됐다',\n",
    "    '일부는 숲에서 발견됐고 일부는 성씨가 소지한 가방 안에 있었다'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "띄어쓰기 기준으로 adjacent sentence graph 를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오패산터널 총격전 용의자 검거 서울 연합뉴스 경찰 관계자들이 19일 오후 서울 강북구 오패산 터널 인근에서 사제 총기를 발사해 경찰을 살해한 용의자 성모씨를 검거하고 있다 성씨는 검거 당시 서바이벌 게임에서 쓰는 방탄조끼에 헬멧까지 착용한 상태였다\n",
      "총격현장 수색하는 경찰들 서울 연합뉴스 이효석 기자 19일 오후 서울 강북구 오패산 터널 인근에서 경찰들이 폭행 용의자가 사제총기를 발사해 경찰관이 사망한 사건을 조사 하고 있다\n",
      "용의자 소지 사제총기 2정 서울 연합뉴스 임헌정 기자 서울 시내에서 폭행 용의자가 현장 조사를 벌이던 경찰관에게 사제총기를 발사해 경찰관이 숨졌다 19일 오후 6시28분 강북구 번동에서 둔기로 맞았다 는 폭행 피해 신고가 접수돼 현장에서 조사하던 강북경찰서 번동파출소 소속 김모 54 경위가 폭행 용의자 성모 45 씨가 쏜 사제총기에 맞고 쓰러진 뒤 병원에 옮겨졌으나 숨졌다 사진은 용의자가 소지한 사제총기\n"
     ]
    }
   ],
   "source": [
    "from textrank import KeysentenceSummarizer\n",
    "\n",
    "summarizer = KeysentenceSummarizer(\n",
    "    tokenize = lambda x:x.split(),\n",
    "    min_sim = 0.3,\n",
    "    verbose = False\n",
    ")\n",
    "keysents = summarizer.summarize(sents, topk=3)\n",
    "for _, _, sent in keysents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KoNLPy 의 Komoran 을 이용하여 토크나이징과 핵심문장을 한 번에 추출하는 예시입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오패산터널 총격전 용의자 검거 서울 연합뉴스 경찰 관계자들이 19일 오후 서울 강북구 오패산 터널 인근에서 사제 총기를 발사해 경찰을 살해한 용의자 성모씨를 검거하고 있다 성씨는 검거 당시 서바이벌 게임에서 쓰는 방탄조끼에 헬멧까지 착용한 상태였다\n",
      "용의자 소지 사제총기 2정 서울 연합뉴스 임헌정 기자 서울 시내에서 폭행 용의자가 현장 조사를 벌이던 경찰관에게 사제총기를 발사해 경찰관이 숨졌다 19일 오후 6시28분 강북구 번동에서 둔기로 맞았다 는 폭행 피해 신고가 접수돼 현장에서 조사하던 강북경찰서 번동파출소 소속 김모 54 경위가 폭행 용의자 성모 45 씨가 쏜 사제총기에 맞고 쓰러진 뒤 병원에 옮겨졌으나 숨졌다 사진은 용의자가 소지한 사제총기\n",
      "신고를 받고 번동파출소에서 김창호 54 경위 등 경찰들이 오후 6시 29분께 현장으로 출동했다 성씨는 그사이 부동산 앞에 놓아뒀던 가방을 챙겨 오패산 쪽으로 도망간 후였다\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Komoran\n",
    "\n",
    "komoran = Komoran()\n",
    "def komoran_tokenizer(sent):\n",
    "    words = komoran.pos(sent, join=True)\n",
    "    words = [w for w in words if ('/NN' in w or '/XR' in w or '/VA' in w or '/VV' in w)]\n",
    "    return words\n",
    "\n",
    "summarizer = KeysentenceSummarizer(\n",
    "    tokenize = komoran_tokenizer,\n",
    "    min_sim = 0.3,\n",
    "    verbose = False\n",
    ")\n",
    "keysents = summarizer.summarize(sents, topk=3)\n",
    "for _, _, sent in keysents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사실 위의 결과를 얻기 위해서는 토크나이저도 제대로 구축할 필요가 없습니다. 어자피 많이 등장한 단어라면 해당 단어를 구성하는 부분어절 (subword) 역시 자주 등장하였을 것이며, 이를 이용한 문장 간 유사도를 측정하여도 비슷하기 때문입니다.\n",
    "\n",
    "아래는 띄어쓰기 기준으로 나뉘어진 어절에서 3음절의 subwords 를 잘라내는 토크나이저 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['이것은',\n",
       " '부분단',\n",
       " '분단어',\n",
       " '단어의',\n",
       " '예시입',\n",
       " '시입니',\n",
       " '입니다',\n",
       " '짧은',\n",
       " '어절은',\n",
       " '그대로',\n",
       " '나옵니',\n",
       " '옵니다']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def subword_tokenizer(sent, n=3):\n",
    "    def subword(token, n):\n",
    "        if len(token) <= n:\n",
    "            return [token]\n",
    "        return [token[i:i+n] for i in range(len(token) - n + 1)]\n",
    "    return [sub for token in sent.split() for sub in subword(token, n)]\n",
    "\n",
    "subword_tokenizer('이것은 부분단어의 예시입니다 짧은 어절은 그대로 나옵니다')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이를 이용하여도 핵심 문장은 위와 동일하게 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오패산터널 총격전 용의자 검거 서울 연합뉴스 경찰 관계자들이 19일 오후 서울 강북구 오패산 터널 인근에서 사제 총기를 발사해 경찰을 살해한 용의자 성모씨를 검거하고 있다 성씨는 검거 당시 서바이벌 게임에서 쓰는 방탄조끼에 헬멧까지 착용한 상태였다\n",
      "용의자 소지 사제총기 2정 서울 연합뉴스 임헌정 기자 서울 시내에서 폭행 용의자가 현장 조사를 벌이던 경찰관에게 사제총기를 발사해 경찰관이 숨졌다 19일 오후 6시28분 강북구 번동에서 둔기로 맞았다 는 폭행 피해 신고가 접수돼 현장에서 조사하던 강북경찰서 번동파출소 소속 김모 54 경위가 폭행 용의자 성모 45 씨가 쏜 사제총기에 맞고 쓰러진 뒤 병원에 옮겨졌으나 숨졌다 사진은 용의자가 소지한 사제총기\n",
      "총격현장 수색하는 경찰들 서울 연합뉴스 이효석 기자 19일 오후 서울 강북구 오패산 터널 인근에서 경찰들이 폭행 용의자가 사제총기를 발사해 경찰관이 사망한 사건을 조사 하고 있다\n"
     ]
    }
   ],
   "source": [
    "summarizer = KeysentenceSummarizer(\n",
    "    tokenize = subword_tokenizer,\n",
    "    min_sim = 0.3,\n",
    "    verbose = False\n",
    ")\n",
    "keysents = summarizer.summarize(sents, topk=3)\n",
    "for _, _, sent in keysents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "summarizer 의 R 에는 각 문장 별 중요도 (PageRank 값) 가 저장되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.76438621, 0.74969733, 1.33782296, 0.61722741, 0.7377122 ,\n",
       "       1.07534516, 0.62928904, 1.71145208, 1.07601036, 1.13590053,\n",
       "       0.94446938, 0.67686714, 0.7008805 , 1.02103025, 1.61461996,\n",
       "       0.76911158, 0.78024047, 0.65793743, 1.02927478, 0.97072522])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer.R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문장의 위치에 따라 중요도를 다르게 설정할 수도 있습니다. 뉴스 기사는 대부분 첫 문장이 중요합니다. 실제로 위의 예시에서도 첫 문장이 가장 중요한 핵심 문장으로 선택되었습니다. 만약 마지막 문장이 중요하다고 가정한다면 이러한 정보를 bias 에 추가할 수 있습니다. numpy.ndarray 형태로 bias 를 만듭니다. 마지막 문장이 다른 문장보다 10 배 중요하다고 가정하였습니다. 이를 summarize 함수의 bias 에 입력하면 가장 먼저 맨 마지막 문장이 중요한 문장으로 선택됩니다. 다른 문장들 중에서도 맨 마지막 문장과 비슷할수록 상대적인 중요도가 더 커집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "일부는 숲에서 발견됐고 일부는 성씨가 소지한 가방 안에 있었다\n",
      "경찰은 인근을 수색해 성씨가 만든 사제총 16정과 칼 7개를 압수했다 실제 폭발할지는 알 수 없는 요구르트병에 무언가를 채워두고 심지를 꽂은 사제 폭탄도 발견됐다\n",
      "오패산터널 총격전 용의자 검거 서울 연합뉴스 경찰 관계자들이 19일 오후 서울 강북구 오패산 터널 인근에서 사제 총기를 발사해 경찰을 살해한 용의자 성모씨를 검거하고 있다 성씨는 검거 당시 서바이벌 게임에서 쓰는 방탄조끼에 헬멧까지 착용한 상태였다\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "bias = np.ones(len(sents))\n",
    "bias[-1] = 10\n",
    "\n",
    "keysents = summarizer.summarize(sents, topk=3, bias=bias)\n",
    "for _, _, sent in keysents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R 을 다시 확인해보면 PageRank 값이 달라졌음을 확인할 수 있습니다. 상대적인 위치 외에도 특정 단어가 포함된 문장에 preference (bias) 를 더 높게 설정할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.22183954, 0.51902092, 0.92584783, 0.42671701, 0.50982682,\n",
       "       0.74430683, 0.43498201, 1.18547126, 0.74505343, 0.78632222,\n",
       "       0.65347844, 0.46802437, 0.48465947, 0.70684359, 1.11845189,\n",
       "       0.53125081, 0.53956034, 0.45476333, 3.14941282, 4.39416707])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
