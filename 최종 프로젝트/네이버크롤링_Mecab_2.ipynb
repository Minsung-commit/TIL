{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "네이버크롤링_Mecab",
      "provenance": [],
      "collapsed_sections": [
        "AW9C899D02Lc"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Minsung-commit/TIL/blob/master/%EB%84%A4%EC%9D%B4%EB%B2%84%ED%81%AC%EB%A1%A4%EB%A7%81_Mecab_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2D3n6CcKAug"
      },
      "source": [
        "%%bash\n",
        "apt-get update\n",
        "apt-get install g++ openjdk-8-jdk python-dev python3-dev\n",
        "pip3 install JPype1\n",
        "pip3 install konlpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "817hwtGGKHHV",
        "outputId": "86ec1c01-d6aa-4288-db4b-5e8b168ea8ec"
      },
      "source": [
        "%env JAVA_HOME \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-amd64\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo2knITZKHhs"
      },
      "source": [
        "%%bash\n",
        "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
        "pip3 install /tmp/mecab-python-0.996"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDVQxjTbKI-K"
      },
      "source": [
        "import konlpy\n",
        "from konlpy.tag import Kkma, Komoran, Hannanum, Okt\n",
        "from konlpy.utils import pprint\n",
        "from konlpy.tag import Mecab"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7HFuujt9pKT"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import time"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEqeF2ku9eHd"
      },
      "source": [
        "data = pd.read_csv('naver_blog_crawling.csv') #데이터셋 로드\n",
        "data = data[['title','content']]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsEiyQPErvhi"
      },
      "source": [
        "data.dropna(axis=0, inplace=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YTguE7ePhtU"
      },
      "source": [
        "# data = data.drop([data.index[1905], data.index[2101]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XW3La0fQ-xRm"
      },
      "source": [
        "#mecab 불러오기\n",
        "mecab = Mecab()\n",
        "okt = Okt()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYqqDUK1_uUY"
      },
      "source": [
        "sample = pd.read_csv('naver_blog_crawling.csv')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4VM2aFR_y1T"
      },
      "source": [
        "sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5xnOqcV-LG6"
      },
      "source": [
        "## 불용어 리스트 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fs4nmArRDxvd"
      },
      "source": [
        "한국어 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgO9xFsarWMw"
      },
      "source": [
        "stop_words = '의 가 이 은 들 는 좀 잘 속초 걍 과 했 거 해서 게 찍 느낌 많이 듯 뷰 ㅎㅎ 너무 게스트 넘 하우스 드리다 이용 위치 쓰다 진짜 넘 찍 거 먹 ㅠㅠ ㅎㅎㅎ ㅠ 물 였 ㅠㅠㅠ ㅠㅠ ㅠ ㅋㅋㅋ ㅋㅋ ㅋ ㅎㅎㅎ ㅎㅎ ㅎ 화장실 도 뭐 오픈 최대 준비 룸 빵 거 많이 방법 달리 스럽다 특별자치도 를 에어비 으로 자 에 와 한 하다 아 휴 아이구 포스팅 아이쿠 아이고 어 나 우리 저희 따라 의해 을 를 에 의 가 으로 로 에게 뿐이다 의거하여 근거하여 입각하여 기준으로 예하면 예를 들면 예를 들자면 저 소인 소생 저희 지말고 하지마 하지마라 다른 물론 또한 그리고 비길수 없다 해서는 안된다 뿐만 아니라 만이 아니다 만은 아니다 막론하고 관계없이 그치지 않다 그러나 그런데 하지만 든간에 논하지 않다 따지지 않다 설사 비록 더라도 아니면 만 못하다 하는 편이 낫다 불문하고 향하여 향해서 향하다 쪽으로 틈타 이용하여 타다 오르다 제외하고 이 외에 이 밖에 하여야 비로소 한다면 몰라도 외에도 이곳 여기 부터 기점으로 따라서 할 생각이다 하려고하다 이리하여 그리하여 그렇게 함으로써 하지만 일때 할때 앞에서 중에서 보는데서 으로써 로써 까지 해야한다 일것이다 반드시 할줄알다 할수있다 할수있어 임에 틀림없다 한다면 등 등등 제 겨우 단지 다만 할뿐 딩동 댕그 대해서 대하여 대하면 훨씬 얼마나 얼마만큼 얼마큼 남짓 이제 분 도움 여 ㅁ ㅎ ㄶ 얼마간 둥 오랜만 약간 체크 체크아웃 가격 정보 비 수기 평일 기준 약 전국  예약 되어다 스마트 빔 블루투스 스피커 이 외 드라이어 다리미 구비 되어다 있다 주방 음식 조리 가능하다 환기 제한 전남 제부도 있다 냄새 나 요리 삼가다 경주시 부탁드리다 후 번길 문의 다 가격 수기 비성수기 주소  좀 조금 다수 몇 얼마 지만 하물며 또한 그러나 그렇지만 하지만 이외에도 대해 말하자면 뿐이다 다음에 반대로 반대로 말하자면 이와 반대로 바꾸어서 말하면 바꾸어서 한다면 만약 그렇지않으면 까악 툭 딱 삐걱거리다 보드득 비걱거리다 꽈당 응당 해야한다 에 가서 각 각각 여러분 각종 각자 제각기 하도록하다 와 과 그러므로 그래서 고로 한 까닭에 하기 때문에 거니와 이지만 대하여 관하여 관한 과연 실로 아니나다를가 생각한대로 진짜로 한적이있다 하곤하였다 하 하하 허허 아하 거바 와 오 왜 어째서 무엇때문에 어찌 하겠는가 무슨 어디 어느곳 더군다나 하물며 더욱이는 어느때 언제 야 이봐 어이 여보시오 흐흐 흥 휴 헉헉 헐떡헐떡 영차 여차 어기여차 끙끙 아야 앗 아야 콸콸 졸졸 좍좍 뚝뚝 주룩주룩 솨 우르르 그래도 또 그리고 바꾸어말하면 바꾸어말하자면 혹은 혹시 답다 및 그에 따르는 때가 되어 즉 지든지 설령 가령 하더라도 할지라도 일지라도 지든지 몇 거의 하마터면 인젠 이젠 된바에야 된이상 만큼 어찌됏든 그위에 게다가 점에서 보아 비추어 보아 고려하면 하게될것이다 일것이다 비교적 좀 보다더 비하면 시키다 하게하다 할만하다 의해서 연이서 이어서 잇따라 포항 우도 양양 전주시 통영 제천 여수시 순천 고성 합천 한림읍 전주 경북 구좌읍 돌산읍 태안 하동 포항시 제주시 밀양 양평 울산 무무 뒤따라 뒤이어 결국 의지하여 기대여 통하여 자마자 더욱더 불구하고 얼마든지 마음대로 주저하지 않고 곧 즉시 바로 당장 하자마자 밖에 안된다 하면된다 그래 그렇지 요컨대 다시 말하자면 바꿔 춘천 층 남해 스테이 서울 여수 거제 추천 경주 곳 객실 이다 강원도 강원 홍천 부산 영도 호 객실 교동 풀빌라 빌라 풀 스튜디오 펜션 말하면 즉 구체적으로 말하자면 시작하여 시초에 이상 허 헉 허걱 바와같이 해도좋다 해도된다 게다가 더구나 하물며 와르르 팍 퍽 펄렁 동안 이래 하고있었다 이었다 에서 로부터 까지 예하면 했어요 해요 함께 같이 더불어 마저 마저도 양자 모두 습니다 가까스로 하려고하다 즈음하여 다른 다른 방면으로 해봐요 습니까 했어요 말할것도 없고 무릎쓰고 개의치않고 하는것만 못하다 하는것이 낫다 매 매번 들 모 어느것 어느 로써 갖고말하자면 어디 어느쪽 어느것 어느해 어느 년도 라 해도 언젠가 어떤것 어느것 저기 저쪽 저것 그때 그럼 그러면 요만한걸 그래 그때 저것만큼 그저 이르기까지 할 줄 안다 할 힘이 있다 너 너희 당신 어찌 설마 차라리 할지언정 할지라도 할망정 할지언정 구토하다 게우다 토하다 메쓰겁다 옆사람 퉤 쳇 의거하여 근거하여 의해 따라 힘입어 그 다음 버금 두번째로 기타 첫번째로 나머지는 그중에서 견지에서 형식으로 쓰여 입장에서 위해서 단지 의해되다 하도록시키다 뿐만아니라 반대로 전후 전자 앞의것 잠시 잠깐 하면서 그렇지만 다음에 그러한즉 그런즉 남들 아무거나 어찌하든지 같다 비슷하다 예컨대 이럴정도로 어떻게 만약 만일 위에서 서술한바와같이 인 듯하다 하지 않는다면 만약에 무엇 무슨 어느 어떤 아래윗 조차 한데 그럼에도 불구하고 여전히 심지어 까지도 조차도 하지 않도록 않기 위하여 때 시각 무렵 시간 동안 어때 어떠한 하여금 네 예 우선 누구 누가 알겠는가 아무도 줄은모른다 줄은 몰랏다 하는 김에 겸사겸사 하는바 그런 까닭에 한 이유는 그러니 그러니까 때문에 그 너희 그들 너희들 타인 것 것들 너 위하여 공동으로 동시에 하기 위하여 어찌하여 무엇때문에 붕붕 윙윙 나 우리 엉엉 휘익 윙윙 오호 아하 어쨋든 만 못하다 하기보다는 차라리 하는 편이 낫다 흐흐 놀라다 상대적으로 말하자면 마치 아니라면 쉿 그렇지 않으면 그렇지 않다면 안 그러면 아니었다면 하든지 아니면 이라면 좋아 알았어 하는것도 그만이다 어쩔수 없다 하나 일 일반적으로 일단 한켠으로는 오자마자 이렇게되면 이와같다면 전부 한마디 한항목 근거로 하기에 아울러 하지 않도록 않기 위해서 이르기까지 이 되다 로 인하여 까닭으로 이유만으로 이로 인하여 그래서 이 때문에 그러므로 그런 까닭에 알 수 있다 결론을 낼 수 있다 으로 인하여 있다 어떤것 관계가 있다 관련이 있다 연관되다 어떤것들 에 대해 이리하여 그리하여 여부 하기보다는 하느니 하면 할수록 운운 이러이러하다 하구나 하도다 다시말하면 다음으로 에 있다 에 달려 있다 우리 우리들 오히려 하기는한데 어떻게 어떻해 어찌됏어 어때 어째서 본대로 자 이 이쪽 여기 이것 이번 이렇게말하자면 이런 이러한 이와 같은 요만큼 요만한 것 얼마 안 되는 것 이만큼 이 정도의 이렇게 많은 것 이와 같다 이때 이렇구나 것과 같이 끼익 삐걱 따위 와 같은 사람들 부류의 사람들 왜냐하면 중의하나 오직 오로지 에 한하다 하기만 하면 도착하다 까지 미치다 도달하다 정도에 이르다 할 지경이다 결과에 이르다 관해서는 여러분 하고 있다 한 후 혼자 자기 자기집 자신 우에 종합한것과같이 총적으로 보면 총적으로 말하면 총적으로 대로 하다 으로서 참 그만이다 할 따름이다 쿵 탕탕 쾅쾅 둥둥 봐 봐라 아이야 아니 와아 응 아이 참나 년 월 일 령 영 일 이 삼 사 오 육 륙 칠 팔 구 이천육 이천칠 이천팔 이천구 하나 둘 셋 넷 다섯 여섯 일곱 여덟 아홉 령 영 이 있 하 것 들 그 되 수 이 보 않 없 나 사람 주 아니 등 같 우리 때 년 가 한 지 대하 오 말 일 그렇 위하 때문 그것 두 말하 알 그러나 받 못하 일 그런 또 문제 더 사회 많 그리고 좋 크 따르 중 나오 가지 씨 시키 만들 지금 생각하 그러 속 하나 집 살 모르 적 월 데 자신 안 어떤 내 내 경우 감성 숙소 호텔 제주 제주도 강원도 강릉 속초 속초시 에어비앤비 명 생각 시간 그녀 수 약 다시 이런 앞 보이 번 나 다른 어떻 여자 개 전 들 사실 이렇 점 싶 말 정도 좀 원 잘 통하 놓' #불용어 리스트 형성"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk2WROfwrYSW"
      },
      "source": [
        "stop_words=stop_words.split(' ')"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qpyB1Vb4x_D"
      },
      "source": [
        "stop_location = pd.read_csv('location_words.csv')\n",
        "stop_location.columns = ['index', 'location']\n",
        "stop_location = stop_location.location.tolist()"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c92Pam2292uK"
      },
      "source": [
        "stop = stop_words + stop_location\n",
        "stop = pd.Series(stop)\n",
        "stopwords = stop.unique().tolist()"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hs8x2Y7yMT_l"
      },
      "source": [
        "## 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TliirW6eSiM9"
      },
      "source": [
        "def tokenize_mec(sent): ## mec 토크나이저\n",
        "  result = []\n",
        "  word_s = mecab.pos(sent)\n",
        "  word = [word for word, tag in word_s if not tag.startswith('E') and not tag.startswith('J') and not tag.startswith('S') and word not in stopwords]\n",
        "  result = word\n",
        "  return result"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlHUCumEPxJb"
      },
      "source": [
        "def tokenize_okt(txt) : # okt 토크나이저\n",
        "    result = []\n",
        "    word_s = okt.pos(txt, norm=True, stem=True)\n",
        "    for n, h in word_s :\n",
        "        if not (h in ['Noun', 'Verb', 'Adjective']) : continue\n",
        "        result.append(n)\n",
        "    return result"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLz67C_-a3cf"
      },
      "source": [
        "data.reset_index(drop=True,inplace=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wph8eaZFcdbZ"
      },
      "source": [
        "# data.content[66]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdvQI1TLMzbt"
      },
      "source": [
        "# tokenize_mec(data.content[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcL-OFxGapE5"
      },
      "source": [
        "data['token_content_mec'] = np.NaN\n",
        "data['token_content_okt'] = np.NaN"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuetwR_TaaJ_",
        "outputId": "c91e0dd0-a480-4d79-e5a8-4d1f56b8396b"
      },
      "source": [
        "for i in range(len(data)):\n",
        "  data['token_content_mec'][i] = tokenize_mec(data.content[i])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODtQrXzuQGL4",
        "outputId": "cbe7763d-005d-4672-b5b6-699f240f7de8"
      },
      "source": [
        "for i in range(len(data)):\n",
        "  data['token_content_okt'][i] = tokenize_okt(data.content[i])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE1CavJPnPDv"
      },
      "source": [
        "for i in range(len(data.content)): #불용어 제거\n",
        "  result = []\n",
        "  for w in data.token_content_okt[i]:\n",
        "    if w not in stop:\n",
        "      result.append(w)\n",
        "    data.token_content_okt[i] = result"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j26NR2X7oQl5"
      },
      "source": [
        "# data.token_content_mec[0]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQlCOafLl1qk"
      },
      "source": [
        "for i in range(len(data.content)): #불용어 제거\n",
        "  result = []\n",
        "  for w in data.token_content_mec[i]:\n",
        "    if w not in stop:\n",
        "      result.append(w)\n",
        "    data.token_content_mec[i] = result"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22JUOS8Alt8K"
      },
      "source": [
        "# data.to_csv('./data.csv', encoding='utf-8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AW9C899D02Lc"
      },
      "source": [
        "# LDA 모델링"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "AEjlRRIN-VtS",
        "outputId": "97c62d65-aa92-4ccd-d388-6886906b1c74"
      },
      "source": [
        "mdl = tp.LDAModel(k=20)\n",
        "\n",
        "for row in text :\n",
        "    mdl.add_doc(row.strip().split())\n",
        "\n",
        "for i in range(0, 100, 10):\n",
        "    mdl.train(10)\n",
        "    print('Iteration: {}\\tLog-likelihood: {}'.format(i, mdl.ll_per_word))\n",
        "\n",
        "for k in range(mdl.k):\n",
        "    print('Top 10 words of topic #{}'.format(k))\n",
        "    print(mdl.get_topic_words(k, top_n=10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-6d326ed62b36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Either `words` or `rawWords` must be filled."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "bbOmxGO1EUY_",
        "outputId": "6439aad4-173e-4efc-f8a7-cc2f5f0011bf"
      },
      "source": [
        "model = tp.LDAModel(k=20, alpha=0.1, eta=0.01, min_cf=5)\n",
        "\n",
        "for i, row in enumerate(text):\n",
        "    model.add_doc(tokenize(row)) # tokenize함수를 이용해 전처리한 결과를 add_doc에 넣습니다.\n",
        "    if i % 10 == 0: print('Document #{} has been loaded'.format(i))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-227a729d3605>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# tokenize함수를 이용해 전처리한 결과를 add_doc에 넣습니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Document #{} has been loaded'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Either `words` or `rawWords` must be filled."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "sWx4f6FQEa6x",
        "outputId": "81dc5876-b8de-47b6-b610-16db4b9cc847"
      },
      "source": [
        "model.train(0)\n",
        "print('Total docs:', len(model.docs))\n",
        "print('Total words:', model.num_words)\n",
        "print('Vocab size:', model.num_vocabs)\n",
        " \n",
        " \n",
        "for i in range(200):\n",
        "    print('Iteration {}\\tLL per word: {}'.format(i, model.ll_per_word))\n",
        "    model.train(1)\n",
        " \n",
        "for i in range(model.k):\n",
        "    res = model.get_topic_words(i, top_n=10)\n",
        "    print('Topic #{}'.format(i), end='\\t')\n",
        "    print(', '.join(w for w, p in res))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1ccc6969856c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Total docs:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Total words:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Vocab size:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_vocabs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LI3svF-gF-23"
      },
      "source": [
        "# LDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c7JNaAmGBGX"
      },
      "source": [
        "## 딕셔너리 및 코퍼스 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCx1qcbpnUbU"
      },
      "source": [
        "# data = pd.read_csv('docs.csv', )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "L8I-6cnbqDTs",
        "outputId": "86e8ba87-b790-470b-8f8b-1a43f2cd96e8"
      },
      "source": [
        "# data.token_content_okt.split()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-f60eca72dd43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_content_okt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'split'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gg8-EV4SICFC"
      },
      "source": [
        "docs = data.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zg4RrA_DoMT0"
      },
      "source": [
        "# docs.to_csv('docs.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1YaB_wMnd2J"
      },
      "source": [
        "docs.token_content_okt[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb8VFp3WpN8z"
      },
      "source": [
        "# [d.split() for d in docs.token_content_okt]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWVxqY20o4B9"
      },
      "source": [
        "docs.token_content_mec[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbAiJKdkyUHJ"
      },
      "source": [
        "np.re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzT_kOBdHarE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "417adb84-2ea8-4129-d87a-0396c56ad7a8"
      },
      "source": [
        "from gensim import corpora\n",
        "dictionary_mec = corpora.Dictionary(docs.token_content_mec)\n",
        "corpus_mec = [dictionary.doc2bow(text) for text in docs.token_content_mec]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-4903466db432>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdictionary_mec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_content_mec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcorpus_mec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_content_mec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/corpora/dictionary.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, documents, prune_at)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdocuments\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprune_at\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprune_at\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/corpora/dictionary.py\u001b[0m in \u001b[0;36madd_documents\u001b[0;34m(self, documents, prune_at)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;31m# update Dictionary with the document\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_update\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ignore the result, here we only care about updating token ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         logger.info(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/corpora/dictionary.py\u001b[0m in \u001b[0;36mdoc2bow\u001b[0;34m(self, document, allow_update, return_missing)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0mcounter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mtoken2id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken2id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: decoding to str: need a bytes-like object, list found"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASVoSag0InqG"
      },
      "source": [
        "from gensim import models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psqM5OToHsQA"
      },
      "source": [
        "## tf-idf 폼 적용\n",
        "tfidf_mec = models.TfidfModel(corpus_mec)\n",
        "corpus_mec = tfidf[corpus_mec]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjL1xWakIxX9"
      },
      "source": [
        "## 학습하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Mhp_GycIWoL"
      },
      "source": [
        "import gensim\n",
        "NUM_TOPICS = 20\n",
        "ldamodel_mec = gensim.models.ldamodel_mec.LdaModel(corpus_mec, num_topics = NUM_TOPICS, id2word=dictionary_mec, passes=15)\n",
        "topics_mec = ldamodel_mec.print_topics(num_words=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jji_4QPUJB-R"
      },
      "source": [
        "# pip install pyLDAvis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k77eY8YIKlqe"
      },
      "source": [
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "pyLDAvis.enable_notebook()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lm6fJlonMHxv"
      },
      "source": [
        "vis = gensimvis.prepare(ldamodel, corpus, dictionary)\n",
        "pyLDAvis.display(vis)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiCga2sXMScQ"
      },
      "source": [
        "#TOMOTOPY_LDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVK2mPRU82qb",
        "outputId": "f3edfdf9-7ff8-43aa-9ece-940764549fe3"
      },
      "source": [
        "! pip install tomotopy #호출\n",
        "import tomotopy as tp"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tomotopy\n",
            "  Downloading tomotopy-0.12.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (16.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 16.3 MB 129 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tomotopy) (1.19.5)\n",
            "Installing collected packages: tomotopy\n",
            "Successfully installed tomotopy-0.12.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17DUZs2QLxW-",
        "outputId": "ac3b450e-1fac-44a4-e296-e3aaaccc3921"
      },
      "source": [
        "for i in range(len(data.content)):\n",
        "  if len(data.token_content_okt[i]) <= 5:\n",
        "    print(i) "
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1905\n",
            "2101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhVjUfRTPKQD"
      },
      "source": [
        "data = data.drop([data.index[1905], data.index[2101]])"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eq4BqvIG9Idy"
      },
      "source": [
        "model = tp.LDAModel(k=20, alpha=0.1, eta=0.01, min_cf=5)\n",
        "# LDAModel을 생성\n",
        "# 토픽의 개수(k)는 20개, alpha 파라미터는 0.1, eta 파라미터는 0.01\n",
        "# 전체 말뭉치에 5회 미만 등장한 단어들은 제거"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NC-roML9Wfb"
      },
      "source": [
        "for row in data.token_content_okt:\n",
        "    model.add_doc(row) # 행 별로 model에 추가합니다."
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmH5G7vo-9uf",
        "outputId": "23b72d80-f8fb-43b1-a3c7-d89fe35c80e9"
      },
      "source": [
        "# model의 num_words나 num_vocabs 등은 train을 시작해야 확정됩니다.\n",
        "# 따라서 이 값을 확인하기 위해서 train(0)을 하여 실제 train은 하지 않고\n",
        "# 학습 준비만 시킵니다.\n",
        "# num_words, num_vocabs에 관심 없다면 이부분은 생략해도 됩니다.\n",
        "model.train(0) \n",
        "print('Total docs:', len(model.docs))\n",
        "print('Total words:', model.num_words)\n",
        "print('Vocab size:', model.num_vocabs)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total docs: 7693\n",
            "Total words: 3660832\n",
            "Vocab size: 15402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeB6n38C_GS5"
      },
      "source": [
        "# 다음 구문은 train을 총 200회 반복하면서, \n",
        "# 매 단계별로 로그 가능도 값을 출력해줍니다.\n",
        "# 혹은 단순히 model.train(200)으로 200회 반복도 가능합니다.\n",
        "for i in range(200):\n",
        "    print('Iteration {}\\tLL per word: {}'.format(i, model.ll_per_word))\n",
        "    model.train(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6AxxsXw_Jxg",
        "outputId": "58ba8148-0dcc-4c7b-e158-a862454611e2"
      },
      "source": [
        "# 학습된 토픽들을 출력해보도록 합시다.\n",
        "for i in range(model.k):\n",
        "    # 토픽 개수가 총 20개이니, 0~19번까지의 토픽별 상위 단어 10개를 뽑아봅시다.\n",
        "    res = model.get_topic_words(i, top_n=10)\n",
        "    print('Topic #{}'.format(i), end='\\t')\n",
        "    print(', '.join(w for w, p in res))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic #0\t하다, 있다, 숙소, 좋다, 강릉, 먹다, 같다, 않다, 들다, 자다\n",
            "Topic #1\t하다, 있다, 곳, 것, 숙소, 같다, 좋다, 수, 공간, 감성\n",
            "Topic #2\t하다, 있다, 것, 없다, 같다, 않다, 보다, 방, 자다, 때\n",
            "Topic #3\t숙소, 에어비앤비, 하다, 있다, 감성, 예쁘다, 호스트, 집, 곳, 좋다\n",
            "Topic #4\t예약, 숙소, 스테이, 인, 하다, 기준, 가격, 감성, 최대, 박\n",
            "Topic #5\t하다, 이다, 있다, 수, 집, 공간, 되다, 보다, 마을, 만들다\n",
            "Topic #6\t제주, 숙소, 제주도, 하다, 감성, 있다, 여행, 좋다, 곳, 이다\n",
            "Topic #7\t하다, 진짜, 우리, 먹다, 넘다, 좋다, 찍다, 오다, 여기, 보다\n",
            "Topic #8\t먹다, 조식, 하다, 카페, 맛있다, 좋다, 있다, 가다, 예쁘다, 맛\n",
            "Topic #9\t있다, 하다, 되어다, 좋다, 공간, 수, 화장실, 주방, 준비, 층\n",
            "Topic #10\t하다, 있다, 펜션, 수영장, 아이, 좋다, 가족, 수, 놀다, 오다\n",
            "Topic #11\t하다, 우리, 보다, 여행, 좋다, 아침, 스테이, 날, 오다, 집\n",
            "Topic #12\t하다, 먹다, 준비, 커피, 있다, 집, 되어다, 날, 아침, 와인\n",
            "Topic #13\t뷰, 바다, 하다, 숙소, 보다, 오션, 층, 있다, 부산, 보이다\n",
            "Topic #14\t하다, 숙소, 좋다, 사진, 찍다, 저, 저희, 이쁘다, 진짜, 있다\n",
            "Topic #15\t하다, 바베큐, 펜션, 있다, 감성, 숙소, 고기, 먹다, 굽다, 캠핑\n",
            "Topic #16\t하다, 있다, 객실, 룸, 이용, 호텔, 되다, 체크, 수, 되어다\n",
            "Topic #17\t있다, 하다, 수, 옥, 숙소, 곳, 것, 좋다, 경주, 이다\n",
            "Topic #18\t하다, 남해, 있다, 풀, 빌라, 스파, 뷰, 펜션, 수, 여수\n",
            "Topic #19\t하다, 예약, 숙소, 탕, 사장, 노천, 있다, 날, 예쁘다, 비\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjLz56Iw_Pvf"
      },
      "source": [
        "# KIWI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSOP0pGeQifB"
      },
      "source": [
        "kiwidata = pd.read_csv('total_blog_dataset.csv')"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOANissPRC21"
      },
      "source": [
        "kiwidata.drop('Unnamed: 0', axis=1, inplace=True)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "dR7gMsm2R1a9",
        "outputId": "36c51f28-3c93-4d9d-fab7-289ec6e452f1"
      },
      "source": [
        "kiwidata"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>['여행', '다녀오다', '게으르다', '여행', '고민', '바라다', '올리다...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['다녀오다', '후기', '휴가', '틈나다', '호캉스', '다녀오다', '다녀...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['여행', '쓰다', '거', '고르다', '아무래도', '여행', '주제', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['오늘', '지나다', '휴가', '찐친', '다녀오다', '메이킷슬', '후기'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['지인', '소개', '#시우재', '마침', '이것저것', '기념일', '재다'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3731</th>\n",
              "      <td>['국내', '여행지', '여행', '맨션자두', '들어가다', '커다랗다', '널...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3732</th>\n",
              "      <td>['영이', '분기', '여행', '스테이솔', '여행지', '편', '영이', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3733</th>\n",
              "      <td>['다귀', '쉼터', '오늘', '째', '하얗다', '외관', '매듭', '스무...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3734</th>\n",
              "      <td>['아파트먼트', '여행', '자주', '불구', '잡다', '놀다', '거', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3735</th>\n",
              "      <td>['포도봉', '미루다', '미루다', '숙소콕', '여행', '다행', '맞추다'...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3736 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                content\n",
              "0     ['여행', '다녀오다', '게으르다', '여행', '고민', '바라다', '올리다...\n",
              "1     ['다녀오다', '후기', '휴가', '틈나다', '호캉스', '다녀오다', '다녀...\n",
              "2     ['여행', '쓰다', '거', '고르다', '아무래도', '여행', '주제', '...\n",
              "3     ['오늘', '지나다', '휴가', '찐친', '다녀오다', '메이킷슬', '후기'...\n",
              "4     ['지인', '소개', '#시우재', '마침', '이것저것', '기념일', '재다'...\n",
              "...                                                 ...\n",
              "3731  ['국내', '여행지', '여행', '맨션자두', '들어가다', '커다랗다', '널...\n",
              "3732  ['영이', '분기', '여행', '스테이솔', '여행지', '편', '영이', '...\n",
              "3733  ['다귀', '쉼터', '오늘', '째', '하얗다', '외관', '매듭', '스무...\n",
              "3734  ['아파트먼트', '여행', '자주', '불구', '잡다', '놀다', '거', '...\n",
              "3735  ['포도봉', '미루다', '미루다', '숙소콕', '여행', '다행', '맞추다'...\n",
              "\n",
              "[3736 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8V-RHdRESMmE",
        "outputId": "92525235-b046-4c64-c110-8bdebb10c83f"
      },
      "source": [
        "len(kiwidata.content[0])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1503"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecEngfA0Si-k"
      },
      "source": [
        "a = kiwidata.content[0]"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7xjMEiBSsdR"
      },
      "source": [
        "#\"\"\"한글빼고 전부 제거\"\"\"\n",
        "def sub_special(s):\n",
        "  return re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣]',' ',s).strip().split()"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71f3huevTo44"
      },
      "source": [
        "for i in range(len(kiwidata)):\n",
        "  kiwidata.content[i] = sub_special(kiwidata.content[i])"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbX-dnNCUJIW"
      },
      "source": [
        "kiwidata.content[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIG8pgA5UKzw"
      },
      "source": [
        "for i in range(len(kiwidata)): #불용어 제거\n",
        "  result = []\n",
        "  for w in kiwidata.content[i]:\n",
        "    if w not in stopwords:\n",
        "      result.append(w)\n",
        "    kiwidata.content[i] = result"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJvUCsT1UcNb"
      },
      "source": [
        "sample = kiwidata.copy()"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEpCtJe7WgCt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3AkmoStWmyV"
      },
      "source": [
        "#TOMOTOPY_LDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jLEL0wYWmyW",
        "outputId": "ee832057-eb87-48d4-b9ab-a1afaaa899d3"
      },
      "source": [
        "! pip install tomotopy #호출\n",
        "import tomotopy as tp"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tomotopy in /usr/local/lib/python3.7/dist-packages (0.12.2)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tomotopy) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1EIcf3rWmyW",
        "outputId": "473cc156-834f-47e2-e2a4-c71992ea73f7"
      },
      "source": [
        "for i in range(len(sample.content)): # 빈 리스트 확인\n",
        "  if len(sample.content[i]) <= 5:\n",
        "    print(i)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1855\n",
            "3400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTNJzuSWWmyW"
      },
      "source": [
        "sample = sample.drop([sample.index[1855],sample.index[3400]])"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCmFFB8TbIBu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zK7R2l8WmyW"
      },
      "source": [
        "model = tp.LDAModel(k=20, alpha=0.1, eta=0.01, min_cf=3)\n",
        "# LDAModel을 생성\n",
        "# 토픽의 개수(k)는 20개, alpha 파라미터는 0.1, eta 파라미터는 0.01\n",
        "# 전체 말뭉치에 5회 미만 등장한 단어들은 제거"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vcfup1psWmyW"
      },
      "source": [
        "for row in sample.content:\n",
        "    model.add_doc(row) # 행 별로 model에 추가합니다."
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPiLODgGWmyW",
        "outputId": "8e742070-e3d6-4ddb-9aff-0f5c72ff4616"
      },
      "source": [
        "# model의 num_words나 num_vocabs 등은 train을 시작해야 확정됩니다.\n",
        "# 따라서 이 값을 확인하기 위해서 train(0)을 하여 실제 train은 하지 않고\n",
        "# 학습 준비만 시킵니다.\n",
        "# num_words, num_vocabs에 관심 없다면 이부분은 생략해도 됩니다.\n",
        "model.train(0) \n",
        "print('Total docs:', len(model.docs))\n",
        "print('Total words:', model.num_words)\n",
        "print('Vocab size:', model.num_vocabs)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total docs: 3734\n",
            "Total words: 887305\n",
            "Vocab size: 14269\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOInH6DZWmyW",
        "outputId": "47a62c9e-b65e-448f-e075-1c7f56ca3fe6"
      },
      "source": [
        "# 다음 구문은 train을 총 200회 반복하면서, \n",
        "# 매 단계별로 로그 가능도 값을 출력해줍니다.\n",
        "# 혹은 단순히 model.train(200)으로 200회 반복도 가능합니다.\n",
        "for i in range(500):\n",
        "    print('Iteration {}\\tLL per word: {}'.format(i, model.ll_per_word))\n",
        "    model.train(1)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0\tLL per word: -11.358827036373226\n",
            "Iteration 1\tLL per word: -10.833454431042341\n",
            "Iteration 2\tLL per word: -10.496505905241323\n",
            "Iteration 3\tLL per word: -10.252356292496634\n",
            "Iteration 4\tLL per word: -10.065234824526655\n",
            "Iteration 5\tLL per word: -9.915904389083307\n",
            "Iteration 6\tLL per word: -9.795649745547609\n",
            "Iteration 7\tLL per word: -9.697118346020362\n",
            "Iteration 8\tLL per word: -9.613508060750043\n",
            "Iteration 9\tLL per word: -9.540708363268388\n",
            "Iteration 10\tLL per word: -9.458786457645461\n",
            "Iteration 11\tLL per word: -9.438469531608234\n",
            "Iteration 12\tLL per word: -9.407515486660266\n",
            "Iteration 13\tLL per word: -9.371929915766453\n",
            "Iteration 14\tLL per word: -9.335513714400022\n",
            "Iteration 15\tLL per word: -9.29652935027258\n",
            "Iteration 16\tLL per word: -9.259967362799223\n",
            "Iteration 17\tLL per word: -9.224587767949192\n",
            "Iteration 18\tLL per word: -9.192720477572399\n",
            "Iteration 19\tLL per word: -9.159711302893943\n",
            "Iteration 20\tLL per word: -9.125769454295412\n",
            "Iteration 21\tLL per word: -9.111161885864679\n",
            "Iteration 22\tLL per word: -9.089984432316111\n",
            "Iteration 23\tLL per word: -9.070204190543263\n",
            "Iteration 24\tLL per word: -9.046711718098543\n",
            "Iteration 25\tLL per word: -9.02435227240688\n",
            "Iteration 26\tLL per word: -9.003562658824137\n",
            "Iteration 27\tLL per word: -8.985945907658431\n",
            "Iteration 28\tLL per word: -8.970456207614493\n",
            "Iteration 29\tLL per word: -8.953368583477198\n",
            "Iteration 30\tLL per word: -8.938039074942157\n",
            "Iteration 31\tLL per word: -8.928422180084183\n",
            "Iteration 32\tLL per word: -8.914835319155204\n",
            "Iteration 33\tLL per word: -8.90148438587697\n",
            "Iteration 34\tLL per word: -8.889666047353385\n",
            "Iteration 35\tLL per word: -8.877411154307449\n",
            "Iteration 36\tLL per word: -8.864015033246048\n",
            "Iteration 37\tLL per word: -8.851005608489958\n",
            "Iteration 38\tLL per word: -8.842336417370896\n",
            "Iteration 39\tLL per word: -8.829619473688973\n",
            "Iteration 40\tLL per word: -8.819281485964781\n",
            "Iteration 41\tLL per word: -8.814560709981098\n",
            "Iteration 42\tLL per word: -8.806593923174331\n",
            "Iteration 43\tLL per word: -8.798896939485969\n",
            "Iteration 44\tLL per word: -8.786890545002208\n",
            "Iteration 45\tLL per word: -8.776471802997053\n",
            "Iteration 46\tLL per word: -8.76769710543836\n",
            "Iteration 47\tLL per word: -8.758868278759044\n",
            "Iteration 48\tLL per word: -8.750607118146736\n",
            "Iteration 49\tLL per word: -8.744396180282623\n",
            "Iteration 50\tLL per word: -8.737247601757636\n",
            "Iteration 51\tLL per word: -8.732099847166676\n",
            "Iteration 52\tLL per word: -8.726590584138926\n",
            "Iteration 53\tLL per word: -8.719992677077512\n",
            "Iteration 54\tLL per word: -8.71438027554936\n",
            "Iteration 55\tLL per word: -8.708451383100769\n",
            "Iteration 56\tLL per word: -8.702693405921044\n",
            "Iteration 57\tLL per word: -8.694775225001365\n",
            "Iteration 58\tLL per word: -8.686747139225893\n",
            "Iteration 59\tLL per word: -8.682574746636742\n",
            "Iteration 60\tLL per word: -8.677724931264866\n",
            "Iteration 61\tLL per word: -8.66974074105877\n",
            "Iteration 62\tLL per word: -8.66460307612454\n",
            "Iteration 63\tLL per word: -8.659736781273986\n",
            "Iteration 64\tLL per word: -8.654678385262766\n",
            "Iteration 65\tLL per word: -8.652197274770144\n",
            "Iteration 66\tLL per word: -8.647948063735546\n",
            "Iteration 67\tLL per word: -8.643221923777972\n",
            "Iteration 68\tLL per word: -8.636720586518235\n",
            "Iteration 69\tLL per word: -8.636285229089987\n",
            "Iteration 70\tLL per word: -8.631924762148357\n",
            "Iteration 71\tLL per word: -8.628068750860447\n",
            "Iteration 72\tLL per word: -8.620776238858946\n",
            "Iteration 73\tLL per word: -8.617875104040571\n",
            "Iteration 74\tLL per word: -8.615873570005045\n",
            "Iteration 75\tLL per word: -8.613439678466909\n",
            "Iteration 76\tLL per word: -8.60908948204434\n",
            "Iteration 77\tLL per word: -8.606348001944907\n",
            "Iteration 78\tLL per word: -8.603456727956715\n",
            "Iteration 79\tLL per word: -8.597948799112414\n",
            "Iteration 80\tLL per word: -8.59442704552112\n",
            "Iteration 81\tLL per word: -8.590908450892869\n",
            "Iteration 82\tLL per word: -8.585519096554437\n",
            "Iteration 83\tLL per word: -8.582351647143506\n",
            "Iteration 84\tLL per word: -8.580241318483155\n",
            "Iteration 85\tLL per word: -8.57871742580988\n",
            "Iteration 86\tLL per word: -8.573972340338601\n",
            "Iteration 87\tLL per word: -8.57027369968542\n",
            "Iteration 88\tLL per word: -8.569643262378445\n",
            "Iteration 89\tLL per word: -8.566557293693457\n",
            "Iteration 90\tLL per word: -8.563817481657914\n",
            "Iteration 91\tLL per word: -8.562155358867647\n",
            "Iteration 92\tLL per word: -8.560350098501436\n",
            "Iteration 93\tLL per word: -8.554703132586077\n",
            "Iteration 94\tLL per word: -8.55353481859444\n",
            "Iteration 95\tLL per word: -8.551657574858755\n",
            "Iteration 96\tLL per word: -8.5484945207654\n",
            "Iteration 97\tLL per word: -8.54752024263235\n",
            "Iteration 98\tLL per word: -8.544511389601748\n",
            "Iteration 99\tLL per word: -8.544034750715602\n",
            "Iteration 100\tLL per word: -8.542067278429036\n",
            "Iteration 101\tLL per word: -8.536522509414217\n",
            "Iteration 102\tLL per word: -8.535689845228807\n",
            "Iteration 103\tLL per word: -8.534428692005886\n",
            "Iteration 104\tLL per word: -8.529478739167484\n",
            "Iteration 105\tLL per word: -8.5299414494994\n",
            "Iteration 106\tLL per word: -8.527429938611268\n",
            "Iteration 107\tLL per word: -8.52541369269902\n",
            "Iteration 108\tLL per word: -8.524943647407248\n",
            "Iteration 109\tLL per word: -8.522956170087578\n",
            "Iteration 110\tLL per word: -8.520699142205151\n",
            "Iteration 111\tLL per word: -8.51936142543198\n",
            "Iteration 112\tLL per word: -8.516427679266943\n",
            "Iteration 113\tLL per word: -8.516521291442666\n",
            "Iteration 114\tLL per word: -8.513954412197004\n",
            "Iteration 115\tLL per word: -8.511480564471533\n",
            "Iteration 116\tLL per word: -8.507666962704823\n",
            "Iteration 117\tLL per word: -8.507255216130211\n",
            "Iteration 118\tLL per word: -8.507158894595403\n",
            "Iteration 119\tLL per word: -8.509248515318658\n",
            "Iteration 120\tLL per word: -8.506650291696095\n",
            "Iteration 121\tLL per word: -8.502544546921776\n",
            "Iteration 122\tLL per word: -8.502082907449214\n",
            "Iteration 123\tLL per word: -8.49895391406691\n",
            "Iteration 124\tLL per word: -8.497962694645787\n",
            "Iteration 125\tLL per word: -8.49727925646336\n",
            "Iteration 126\tLL per word: -8.495216721544983\n",
            "Iteration 127\tLL per word: -8.492444227451923\n",
            "Iteration 128\tLL per word: -8.491894181419045\n",
            "Iteration 129\tLL per word: -8.491239926079107\n",
            "Iteration 130\tLL per word: -8.491243170450616\n",
            "Iteration 131\tLL per word: -8.490076479398912\n",
            "Iteration 132\tLL per word: -8.489993197997084\n",
            "Iteration 133\tLL per word: -8.487889144836656\n",
            "Iteration 134\tLL per word: -8.485078830357208\n",
            "Iteration 135\tLL per word: -8.483999980279917\n",
            "Iteration 136\tLL per word: -8.480958837429535\n",
            "Iteration 137\tLL per word: -8.479884513708086\n",
            "Iteration 138\tLL per word: -8.477126345918162\n",
            "Iteration 139\tLL per word: -8.47490120935399\n",
            "Iteration 140\tLL per word: -8.47307259419058\n",
            "Iteration 141\tLL per word: -8.471989048902934\n",
            "Iteration 142\tLL per word: -8.47002640879719\n",
            "Iteration 143\tLL per word: -8.468329353792267\n",
            "Iteration 144\tLL per word: -8.467238696503944\n",
            "Iteration 145\tLL per word: -8.46298818363058\n",
            "Iteration 146\tLL per word: -8.464728257543475\n",
            "Iteration 147\tLL per word: -8.465588413404939\n",
            "Iteration 148\tLL per word: -8.462536155025605\n",
            "Iteration 149\tLL per word: -8.463169969598244\n",
            "Iteration 150\tLL per word: -8.463104670786825\n",
            "Iteration 151\tLL per word: -8.460293329190227\n",
            "Iteration 152\tLL per word: -8.458577748413465\n",
            "Iteration 153\tLL per word: -8.460197978561595\n",
            "Iteration 154\tLL per word: -8.458449444919232\n",
            "Iteration 155\tLL per word: -8.456278583222284\n",
            "Iteration 156\tLL per word: -8.456130264956814\n",
            "Iteration 157\tLL per word: -8.457016597468519\n",
            "Iteration 158\tLL per word: -8.453606146464475\n",
            "Iteration 159\tLL per word: -8.452616210117169\n",
            "Iteration 160\tLL per word: -8.452607362587377\n",
            "Iteration 161\tLL per word: -8.44952759368774\n",
            "Iteration 162\tLL per word: -8.449510832116442\n",
            "Iteration 163\tLL per word: -8.450228705115325\n",
            "Iteration 164\tLL per word: -8.448417865453502\n",
            "Iteration 165\tLL per word: -8.44856385632098\n",
            "Iteration 166\tLL per word: -8.449076086920254\n",
            "Iteration 167\tLL per word: -8.448133688432673\n",
            "Iteration 168\tLL per word: -8.44726914586423\n",
            "Iteration 169\tLL per word: -8.447929905358746\n",
            "Iteration 170\tLL per word: -8.444624197383131\n",
            "Iteration 171\tLL per word: -8.442415185568892\n",
            "Iteration 172\tLL per word: -8.440660462202606\n",
            "Iteration 173\tLL per word: -8.442645984587838\n",
            "Iteration 174\tLL per word: -8.44143520975803\n",
            "Iteration 175\tLL per word: -8.439189890647466\n",
            "Iteration 176\tLL per word: -8.440240504446733\n",
            "Iteration 177\tLL per word: -8.440484033485482\n",
            "Iteration 178\tLL per word: -8.439744089751658\n",
            "Iteration 179\tLL per word: -8.435338935776292\n",
            "Iteration 180\tLL per word: -8.435765464052992\n",
            "Iteration 181\tLL per word: -8.433297830423014\n",
            "Iteration 182\tLL per word: -8.43179261402906\n",
            "Iteration 183\tLL per word: -8.433567813690187\n",
            "Iteration 184\tLL per word: -8.435789901321186\n",
            "Iteration 185\tLL per word: -8.431970485190117\n",
            "Iteration 186\tLL per word: -8.430930629811686\n",
            "Iteration 187\tLL per word: -8.431503922971856\n",
            "Iteration 188\tLL per word: -8.431445869851778\n",
            "Iteration 189\tLL per word: -8.43097699713069\n",
            "Iteration 190\tLL per word: -8.427129540574123\n",
            "Iteration 191\tLL per word: -8.427137485994798\n",
            "Iteration 192\tLL per word: -8.428520338285047\n",
            "Iteration 193\tLL per word: -8.424863238811708\n",
            "Iteration 194\tLL per word: -8.426761478121014\n",
            "Iteration 195\tLL per word: -8.425910712059201\n",
            "Iteration 196\tLL per word: -8.426402318325279\n",
            "Iteration 197\tLL per word: -8.424096384261116\n",
            "Iteration 198\tLL per word: -8.422466654405463\n",
            "Iteration 199\tLL per word: -8.42221159425527\n",
            "Iteration 200\tLL per word: -8.422149668198283\n",
            "Iteration 201\tLL per word: -8.419210795402693\n",
            "Iteration 202\tLL per word: -8.418212414756555\n",
            "Iteration 203\tLL per word: -8.418914869111346\n",
            "Iteration 204\tLL per word: -8.421138412241218\n",
            "Iteration 205\tLL per word: -8.420240500988019\n",
            "Iteration 206\tLL per word: -8.420447170575898\n",
            "Iteration 207\tLL per word: -8.419350958302376\n",
            "Iteration 208\tLL per word: -8.419317047119412\n",
            "Iteration 209\tLL per word: -8.417619318611715\n",
            "Iteration 210\tLL per word: -8.41852349378611\n",
            "Iteration 211\tLL per word: -8.41652207758375\n",
            "Iteration 212\tLL per word: -8.416255841657428\n",
            "Iteration 213\tLL per word: -8.41405254838705\n",
            "Iteration 214\tLL per word: -8.413950759892067\n",
            "Iteration 215\tLL per word: -8.414349155598478\n",
            "Iteration 216\tLL per word: -8.415869048172027\n",
            "Iteration 217\tLL per word: -8.41411952844354\n",
            "Iteration 218\tLL per word: -8.41337076278535\n",
            "Iteration 219\tLL per word: -8.412628624830639\n",
            "Iteration 220\tLL per word: -8.413560156854611\n",
            "Iteration 221\tLL per word: -8.412237202100345\n",
            "Iteration 222\tLL per word: -8.410893513779751\n",
            "Iteration 223\tLL per word: -8.409283293883213\n",
            "Iteration 224\tLL per word: -8.408714740392082\n",
            "Iteration 225\tLL per word: -8.409563626646738\n",
            "Iteration 226\tLL per word: -8.407197589647739\n",
            "Iteration 227\tLL per word: -8.406421997874258\n",
            "Iteration 228\tLL per word: -8.405531487452675\n",
            "Iteration 229\tLL per word: -8.404021831678563\n",
            "Iteration 230\tLL per word: -8.405090897547796\n",
            "Iteration 231\tLL per word: -8.404638162950397\n",
            "Iteration 232\tLL per word: -8.403329884342725\n",
            "Iteration 233\tLL per word: -8.403427292405434\n",
            "Iteration 234\tLL per word: -8.40258066833245\n",
            "Iteration 235\tLL per word: -8.402182813403194\n",
            "Iteration 236\tLL per word: -8.401379456026994\n",
            "Iteration 237\tLL per word: -8.401284680340055\n",
            "Iteration 238\tLL per word: -8.401824462165568\n",
            "Iteration 239\tLL per word: -8.399415166881372\n",
            "Iteration 240\tLL per word: -8.397891267648014\n",
            "Iteration 241\tLL per word: -8.398854249808968\n",
            "Iteration 242\tLL per word: -8.39935306355807\n",
            "Iteration 243\tLL per word: -8.399225164441345\n",
            "Iteration 244\tLL per word: -8.397821811378035\n",
            "Iteration 245\tLL per word: -8.397531027295415\n",
            "Iteration 246\tLL per word: -8.396295354974324\n",
            "Iteration 247\tLL per word: -8.396329769595203\n",
            "Iteration 248\tLL per word: -8.396076089302353\n",
            "Iteration 249\tLL per word: -8.396485145664688\n",
            "Iteration 250\tLL per word: -8.397242374449712\n",
            "Iteration 251\tLL per word: -8.398323974100643\n",
            "Iteration 252\tLL per word: -8.399659266498112\n",
            "Iteration 253\tLL per word: -8.398783724082001\n",
            "Iteration 254\tLL per word: -8.400652252583724\n",
            "Iteration 255\tLL per word: -8.399027966418675\n",
            "Iteration 256\tLL per word: -8.397093732384294\n",
            "Iteration 257\tLL per word: -8.396612881278124\n",
            "Iteration 258\tLL per word: -8.396235144639396\n",
            "Iteration 259\tLL per word: -8.395443940666638\n",
            "Iteration 260\tLL per word: -8.395467546060113\n",
            "Iteration 261\tLL per word: -8.394591487552924\n",
            "Iteration 262\tLL per word: -8.391333164221532\n",
            "Iteration 263\tLL per word: -8.39200668033878\n",
            "Iteration 264\tLL per word: -8.392159272076562\n",
            "Iteration 265\tLL per word: -8.391302814989599\n",
            "Iteration 266\tLL per word: -8.389992396420459\n",
            "Iteration 267\tLL per word: -8.388501725445341\n",
            "Iteration 268\tLL per word: -8.389183850164834\n",
            "Iteration 269\tLL per word: -8.391029699178194\n",
            "Iteration 270\tLL per word: -8.39299837935932\n",
            "Iteration 271\tLL per word: -8.391218695891872\n",
            "Iteration 272\tLL per word: -8.392151725416536\n",
            "Iteration 273\tLL per word: -8.391019132545013\n",
            "Iteration 274\tLL per word: -8.389962020453419\n",
            "Iteration 275\tLL per word: -8.389362874767375\n",
            "Iteration 276\tLL per word: -8.387781151105926\n",
            "Iteration 277\tLL per word: -8.3898514632858\n",
            "Iteration 278\tLL per word: -8.389014967275504\n",
            "Iteration 279\tLL per word: -8.387072643937348\n",
            "Iteration 280\tLL per word: -8.38780742288042\n",
            "Iteration 281\tLL per word: -8.386897700008001\n",
            "Iteration 282\tLL per word: -8.386720683203272\n",
            "Iteration 283\tLL per word: -8.387634577820704\n",
            "Iteration 284\tLL per word: -8.38805651663774\n",
            "Iteration 285\tLL per word: -8.385890579459192\n",
            "Iteration 286\tLL per word: -8.386845209467085\n",
            "Iteration 287\tLL per word: -8.38711904261259\n",
            "Iteration 288\tLL per word: -8.386128931075183\n",
            "Iteration 289\tLL per word: -8.386244200032793\n",
            "Iteration 290\tLL per word: -8.386827080007937\n",
            "Iteration 291\tLL per word: -8.38542237117783\n",
            "Iteration 292\tLL per word: -8.385556261822156\n",
            "Iteration 293\tLL per word: -8.38384935488743\n",
            "Iteration 294\tLL per word: -8.382252563164212\n",
            "Iteration 295\tLL per word: -8.384619581467145\n",
            "Iteration 296\tLL per word: -8.38700149948034\n",
            "Iteration 297\tLL per word: -8.386205482903415\n",
            "Iteration 298\tLL per word: -8.385916122899353\n",
            "Iteration 299\tLL per word: -8.384967519254323\n",
            "Iteration 300\tLL per word: -8.382144068924418\n",
            "Iteration 301\tLL per word: -8.382011375715436\n",
            "Iteration 302\tLL per word: -8.381757971834306\n",
            "Iteration 303\tLL per word: -8.37985923496121\n",
            "Iteration 304\tLL per word: -8.379878528039445\n",
            "Iteration 305\tLL per word: -8.381080021942886\n",
            "Iteration 306\tLL per word: -8.38296423336386\n",
            "Iteration 307\tLL per word: -8.380823660853546\n",
            "Iteration 308\tLL per word: -8.380291212912734\n",
            "Iteration 309\tLL per word: -8.38096281154055\n",
            "Iteration 310\tLL per word: -8.378553046813987\n",
            "Iteration 311\tLL per word: -8.378967130927277\n",
            "Iteration 312\tLL per word: -8.377864311604899\n",
            "Iteration 313\tLL per word: -8.378460589007474\n",
            "Iteration 314\tLL per word: -8.377932312522622\n",
            "Iteration 315\tLL per word: -8.375747671548083\n",
            "Iteration 316\tLL per word: -8.376949085721561\n",
            "Iteration 317\tLL per word: -8.376749508508896\n",
            "Iteration 318\tLL per word: -8.37707380299123\n",
            "Iteration 319\tLL per word: -8.375325255907756\n",
            "Iteration 320\tLL per word: -8.378872053391452\n",
            "Iteration 321\tLL per word: -8.377613686165853\n",
            "Iteration 322\tLL per word: -8.375558395288525\n",
            "Iteration 323\tLL per word: -8.378604649527976\n",
            "Iteration 324\tLL per word: -8.377194946071679\n",
            "Iteration 325\tLL per word: -8.378482523804088\n",
            "Iteration 326\tLL per word: -8.377936998621363\n",
            "Iteration 327\tLL per word: -8.377569795085094\n",
            "Iteration 328\tLL per word: -8.375387719027778\n",
            "Iteration 329\tLL per word: -8.377852599972092\n",
            "Iteration 330\tLL per word: -8.375906388642887\n",
            "Iteration 331\tLL per word: -8.373632851475055\n",
            "Iteration 332\tLL per word: -8.374076164434983\n",
            "Iteration 333\tLL per word: -8.372429264035928\n",
            "Iteration 334\tLL per word: -8.373226390081289\n",
            "Iteration 335\tLL per word: -8.371900567970487\n",
            "Iteration 336\tLL per word: -8.372106773183159\n",
            "Iteration 337\tLL per word: -8.373581577633143\n",
            "Iteration 338\tLL per word: -8.37317729750071\n",
            "Iteration 339\tLL per word: -8.373564718511977\n",
            "Iteration 340\tLL per word: -8.375418910259222\n",
            "Iteration 341\tLL per word: -8.372842479262978\n",
            "Iteration 342\tLL per word: -8.3745014020164\n",
            "Iteration 343\tLL per word: -8.374105510906645\n",
            "Iteration 344\tLL per word: -8.372637384165731\n",
            "Iteration 345\tLL per word: -8.370769389312956\n",
            "Iteration 346\tLL per word: -8.372179395629296\n",
            "Iteration 347\tLL per word: -8.370816508903985\n",
            "Iteration 348\tLL per word: -8.37029592448148\n",
            "Iteration 349\tLL per word: -8.371667323840077\n",
            "Iteration 350\tLL per word: -8.371059113225586\n",
            "Iteration 351\tLL per word: -8.370374011773785\n",
            "Iteration 352\tLL per word: -8.368514895086482\n",
            "Iteration 353\tLL per word: -8.368553878098512\n",
            "Iteration 354\tLL per word: -8.369888844750035\n",
            "Iteration 355\tLL per word: -8.371218226405565\n",
            "Iteration 356\tLL per word: -8.371884925261924\n",
            "Iteration 357\tLL per word: -8.370485996241802\n",
            "Iteration 358\tLL per word: -8.37011039911472\n",
            "Iteration 359\tLL per word: -8.368640675697803\n",
            "Iteration 360\tLL per word: -8.36998920752004\n",
            "Iteration 361\tLL per word: -8.366803884198145\n",
            "Iteration 362\tLL per word: -8.369893289380485\n",
            "Iteration 363\tLL per word: -8.369555210680987\n",
            "Iteration 364\tLL per word: -8.369167904929357\n",
            "Iteration 365\tLL per word: -8.36766767545937\n",
            "Iteration 366\tLL per word: -8.367972981973399\n",
            "Iteration 367\tLL per word: -8.368149531059911\n",
            "Iteration 368\tLL per word: -8.369239189083357\n",
            "Iteration 369\tLL per word: -8.369574942188144\n",
            "Iteration 370\tLL per word: -8.370197485847498\n",
            "Iteration 371\tLL per word: -8.37175647245387\n",
            "Iteration 372\tLL per word: -8.372037599648811\n",
            "Iteration 373\tLL per word: -8.373390048071359\n",
            "Iteration 374\tLL per word: -8.372212086211883\n",
            "Iteration 375\tLL per word: -8.371226032201061\n",
            "Iteration 376\tLL per word: -8.370019247364503\n",
            "Iteration 377\tLL per word: -8.370400100063621\n",
            "Iteration 378\tLL per word: -8.369955096382172\n",
            "Iteration 379\tLL per word: -8.371284713373324\n",
            "Iteration 380\tLL per word: -8.369480507695416\n",
            "Iteration 381\tLL per word: -8.370156747740614\n",
            "Iteration 382\tLL per word: -8.365743578313394\n",
            "Iteration 383\tLL per word: -8.365253611106404\n",
            "Iteration 384\tLL per word: -8.365178063508935\n",
            "Iteration 385\tLL per word: -8.36719891250917\n",
            "Iteration 386\tLL per word: -8.366814231030219\n",
            "Iteration 387\tLL per word: -8.36678856365138\n",
            "Iteration 388\tLL per word: -8.368440345121957\n",
            "Iteration 389\tLL per word: -8.368109462915363\n",
            "Iteration 390\tLL per word: -8.367554930258352\n",
            "Iteration 391\tLL per word: -8.36612437957956\n",
            "Iteration 392\tLL per word: -8.36538283762458\n",
            "Iteration 393\tLL per word: -8.36487557423953\n",
            "Iteration 394\tLL per word: -8.365122440655623\n",
            "Iteration 395\tLL per word: -8.364201938471613\n",
            "Iteration 396\tLL per word: -8.362772918431661\n",
            "Iteration 397\tLL per word: -8.363921377811593\n",
            "Iteration 398\tLL per word: -8.365324547391241\n",
            "Iteration 399\tLL per word: -8.367261985684557\n",
            "Iteration 400\tLL per word: -8.366570408119932\n",
            "Iteration 401\tLL per word: -8.366461243758527\n",
            "Iteration 402\tLL per word: -8.366103292548464\n",
            "Iteration 403\tLL per word: -8.3680713444216\n",
            "Iteration 404\tLL per word: -8.36774855044765\n",
            "Iteration 405\tLL per word: -8.367376340075998\n",
            "Iteration 406\tLL per word: -8.365244799594915\n",
            "Iteration 407\tLL per word: -8.365919012937882\n",
            "Iteration 408\tLL per word: -8.365048915426684\n",
            "Iteration 409\tLL per word: -8.363904064498003\n",
            "Iteration 410\tLL per word: -8.362459704550815\n",
            "Iteration 411\tLL per word: -8.363615571420336\n",
            "Iteration 412\tLL per word: -8.363857470378154\n",
            "Iteration 413\tLL per word: -8.364385440153935\n",
            "Iteration 414\tLL per word: -8.36424139636448\n",
            "Iteration 415\tLL per word: -8.362690219979733\n",
            "Iteration 416\tLL per word: -8.36275389683988\n",
            "Iteration 417\tLL per word: -8.363007623616099\n",
            "Iteration 418\tLL per word: -8.363711178685428\n",
            "Iteration 419\tLL per word: -8.365288704059207\n",
            "Iteration 420\tLL per word: -8.364571164447248\n",
            "Iteration 421\tLL per word: -8.363781056318928\n",
            "Iteration 422\tLL per word: -8.363516613947763\n",
            "Iteration 423\tLL per word: -8.365815049887305\n",
            "Iteration 424\tLL per word: -8.36524041065759\n",
            "Iteration 425\tLL per word: -8.365032138424683\n",
            "Iteration 426\tLL per word: -8.36756051582582\n",
            "Iteration 427\tLL per word: -8.366170577353408\n",
            "Iteration 428\tLL per word: -8.366861994578073\n",
            "Iteration 429\tLL per word: -8.365838197829374\n",
            "Iteration 430\tLL per word: -8.367747173417277\n",
            "Iteration 431\tLL per word: -8.367909034499066\n",
            "Iteration 432\tLL per word: -8.367999678378434\n",
            "Iteration 433\tLL per word: -8.365978874594973\n",
            "Iteration 434\tLL per word: -8.364264782691862\n",
            "Iteration 435\tLL per word: -8.365692132192606\n",
            "Iteration 436\tLL per word: -8.366056374446819\n",
            "Iteration 437\tLL per word: -8.366578598035302\n",
            "Iteration 438\tLL per word: -8.365586444381066\n",
            "Iteration 439\tLL per word: -8.366634286962492\n",
            "Iteration 440\tLL per word: -8.365739151165561\n",
            "Iteration 441\tLL per word: -8.365316091894888\n",
            "Iteration 442\tLL per word: -8.365702951516052\n",
            "Iteration 443\tLL per word: -8.364298790201454\n",
            "Iteration 444\tLL per word: -8.365614644815135\n",
            "Iteration 445\tLL per word: -8.36343844247877\n",
            "Iteration 446\tLL per word: -8.364818453278248\n",
            "Iteration 447\tLL per word: -8.363708596920786\n",
            "Iteration 448\tLL per word: -8.36428334320121\n",
            "Iteration 449\tLL per word: -8.366227429824006\n",
            "Iteration 450\tLL per word: -8.364933888522089\n",
            "Iteration 451\tLL per word: -8.364778478072019\n",
            "Iteration 452\tLL per word: -8.364357233596976\n",
            "Iteration 453\tLL per word: -8.364474436021505\n",
            "Iteration 454\tLL per word: -8.365195341176818\n",
            "Iteration 455\tLL per word: -8.365242456160917\n",
            "Iteration 456\tLL per word: -8.366576662732983\n",
            "Iteration 457\tLL per word: -8.366192740861399\n",
            "Iteration 458\tLL per word: -8.36790880916913\n",
            "Iteration 459\tLL per word: -8.365476483687088\n",
            "Iteration 460\tLL per word: -8.36397066140825\n",
            "Iteration 461\tLL per word: -8.365149421477147\n",
            "Iteration 462\tLL per word: -8.365083951823962\n",
            "Iteration 463\tLL per word: -8.36431465668418\n",
            "Iteration 464\tLL per word: -8.364801633102267\n",
            "Iteration 465\tLL per word: -8.364913418945624\n",
            "Iteration 466\tLL per word: -8.363629256130654\n",
            "Iteration 467\tLL per word: -8.363937439046692\n",
            "Iteration 468\tLL per word: -8.364998149400845\n",
            "Iteration 469\tLL per word: -8.364010355472628\n",
            "Iteration 470\tLL per word: -8.362718257322877\n",
            "Iteration 471\tLL per word: -8.3642553352595\n",
            "Iteration 472\tLL per word: -8.36320425670771\n",
            "Iteration 473\tLL per word: -8.364068267087205\n",
            "Iteration 474\tLL per word: -8.363161948893287\n",
            "Iteration 475\tLL per word: -8.363818617744581\n",
            "Iteration 476\tLL per word: -8.362139726249733\n",
            "Iteration 477\tLL per word: -8.36229212762444\n",
            "Iteration 478\tLL per word: -8.36240087002232\n",
            "Iteration 479\tLL per word: -8.362929251865904\n",
            "Iteration 480\tLL per word: -8.36260489405756\n",
            "Iteration 481\tLL per word: -8.361659037299324\n",
            "Iteration 482\tLL per word: -8.360530732374619\n",
            "Iteration 483\tLL per word: -8.35968861195816\n",
            "Iteration 484\tLL per word: -8.361388846968392\n",
            "Iteration 485\tLL per word: -8.360372353337452\n",
            "Iteration 486\tLL per word: -8.359985430596765\n",
            "Iteration 487\tLL per word: -8.358560170910856\n",
            "Iteration 488\tLL per word: -8.358252482867472\n",
            "Iteration 489\tLL per word: -8.358427224002199\n",
            "Iteration 490\tLL per word: -8.358450774204254\n",
            "Iteration 491\tLL per word: -8.358305006543224\n",
            "Iteration 492\tLL per word: -8.357717811471085\n",
            "Iteration 493\tLL per word: -8.358344608848565\n",
            "Iteration 494\tLL per word: -8.358578277252285\n",
            "Iteration 495\tLL per word: -8.358905757516533\n",
            "Iteration 496\tLL per word: -8.357263608977394\n",
            "Iteration 497\tLL per word: -8.359164343774848\n",
            "Iteration 498\tLL per word: -8.358197834929772\n",
            "Iteration 499\tLL per word: -8.359021092217269\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2wD0hd_WmyX",
        "outputId": "520a81a8-3c7c-46de-b83f-2f6dcf935490"
      },
      "source": [
        "# 학습된 토픽들을 출력해보도록 합시다.\n",
        "for i in range(model.k):\n",
        "    # 토픽 개수가 총 20개이니, 0~19번까지의 토픽별 상위 단어 10개를 뽑아봅시다.\n",
        "    res = model.get_topic_words(i, top_n=10)\n",
        "    print('Topic #{}'.format(i), end='\\t')\n",
        "    print(', '.join(w for w, p in res))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic #0\t먹다, 친구, 와인, 맛, 맛있다, 술, 놀다, 파티, 잔, 저녁\n",
            "Topic #1\t님, 사장, 정말, 날, 여행, 아침, 친절, 직접, 손, 남편\n",
            "Topic #2\t앉다, 춥다, 날, 언니, 멍, 그냥, 밤, 바람, 버리다, 소리\n",
            "Topic #3\t박, 링크, 인스타그램, 할인, 성수기, 홈페이지, 주말, 블로그, 인원, 추가\n",
            "Topic #4\t공간, 거실, 문, 침대, 열다, 침실, 옆, 들어가다, 커피, 들어오다\n",
            "Topic #5\t찍다, 넘다, 이쁘다, 예쁘다, 먹다, 날, 못, 그냥, 들어가다, 아침\n",
            "Topic #6\t수영장, 욕조, 즐기다, 야외, 탕, 자쿠지, 채, 스파, 침실, 바베큐\n",
            "Topic #7\t가족, 여행, 엄마, 놀다, 예쁘다, 리조트, 아기, 정원, 좋아하다, 꽃\n",
            "Topic #8\t공간, 느끼다, 즐기다, 마음, 여행, 보내다, 풍경, 편안, 분위기, 힐링\n",
            "Topic #9\t광안리, 캠핑, 반, 라운드, 스파, 제공, 카라, 건물, 폴리, 즐기다\n",
            "Topic #10\t깔끔, 정말, 깨끗, 침대, 만족, 들어가다, 아쉽다, 주차, 테라스, 불편\n",
            "Topic #11\t돌담, 박, 여행, 거리, 민박, 애, 제주감성숙소, 귤, 채, 동쪽\n",
            "Topic #12\t여행, 카페, 건물, 근처, 거리, 찾다, 박, 후기, 숙박, 다녀오다\n",
            "Topic #13\t바베큐, 먹다, 굽다, 맛있다, 놀다, 캠핑, 불, 마트, 추가, 챙기다\n",
            "Topic #14\t예쁘다, 정말, 인테리어, 공간, 분위기, 소품, 여행, 화이트, 깔끔, 조명\n",
            "Topic #15\t샴푸, 수건, 치약, 칫솔, 사용, 냉장고, 챙기다, 드라이, 커피, 린스\n",
            "Topic #16\t바다, 오션뷰, 해변, 풍경, 아침, 해수욕장, 노을, 하늘, 바라보다, 카페\n",
            "Topic #17\t한옥, 마당, 채, 독, 황리단, 한적, 마루, 독채, 황리단길, 별채\n",
            "Topic #18\t조식, 먹다, 카페, 맛있다, 맛, 아침, 커피, 제공, 날, 음료\n",
            "Topic #19\t거제도, 탕, 여관, 온도, 아날로그, 바다, 히노끼탕, 여행, 적정, 즐기다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfrebpiWbWsy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}